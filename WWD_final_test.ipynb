{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T21:15:47.318230Z",
     "start_time": "2025-11-30T21:15:43.676441Z"
    }
   },
   "source": [
    "!pip install librosa\n",
    "!pip install sounddevice soundfile numpy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.5.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: soundfile in c:\\users\\danma\\miniconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\danma\\miniconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\danma\\miniconda3\\lib\\site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\danma\\miniconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Downloading sounddevice-0.5.3-py3-none-win_amd64.whl (364 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:34:30.451947Z",
     "start_time": "2025-11-30T22:34:30.447913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import time\n",
    "\n",
    "SAMPLE_RATE = 16000 # Please don't change\n",
    "WINDOW_SIZE = 3.0\n",
    "STRIDE = 1.0\n",
    "\n",
    "MIC_RATE = 44100\n",
    "\n",
    "WINDOW_SAMPLES = SAMPLE_RATE * WINDOW_SIZE\n",
    "STRIDE_SAMPLES = SAMPLE_RATE * STRIDE\n"
   ],
   "id": "e996af043fb013ed",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>MEL</h3>",
   "id": "57c5baed4faa50a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:19:28.225306Z",
     "start_time": "2025-11-30T22:19:28.214371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "def generate_mel(y):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=SAMPLE_RATE,\n",
    "            n_fft=512,\n",
    "            hop_length=160,\n",
    "            n_mels=40\n",
    "        )\n",
    "    mel = librosa.power_to_db(mel, ref=np.max).astype(np.float32)\n",
    "    return torch.from_numpy(mel).float()"
   ],
   "id": "71f6a360caa371b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Model</h3>",
   "id": "cd64053285352043"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:19:32.391508Z",
     "start_time": "2025-11-30T22:19:29.960511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch    \n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=4, kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_channels * expansion\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding, stride=stride),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.use_residual:\n",
    "            out += x\n",
    "        return out\n",
    "    \n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes = 1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            MBConvBlock(1,16, expansion=4),\n",
    "            MBConvBlock(16, 32, expansion=4,stride=2),\n",
    "            MBConvBlock(32, 64, expansion=4,stride=2)\n",
    "        )\n",
    "        self.rnn = nn.GRU(64, 256, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.mean(dim=2)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        _, h = self.rnn(x)\n",
    "        h = h.permute(1, 0, 2)\n",
    "        h = h.contiguous().view(x.size(0), -1)\n",
    "        out = self.fc(h)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "model = CRNN()\n",
    "model.load_state_dict(torch.load(\"trained_models/worst_crnn_with_mbconv_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def wake_word_detect(data):\n",
    "    mel = generate_mel(data).unsqueeze(0).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out = model(mel).squeeze()\n",
    "        print(out)\n",
    "        pred = (out > 0.5).float()\n",
    "        if pred == 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ],
   "id": "9f9b1b91ae0ce74a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:33:47.348359Z",
     "start_time": "2025-11-30T22:33:47.343848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "dev = sd.query_devices(sd.default.device[0], 'input')\n",
    "print(dev)\n",
    "print(\"Sample rate:\", dev['default_samplerate'])\n"
   ],
   "id": "9b9bcd0dc7088f12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Mikrofonarray (Realtek(R) Audio', 'index': 1, 'hostapi': 0, 'max_input_channels': 2, 'max_output_channels': 0, 'default_low_input_latency': 0.09, 'default_low_output_latency': 0.09, 'default_high_input_latency': 0.18, 'default_high_output_latency': 0.18, 'default_samplerate': 44100.0}\n",
      "Sample rate: 44100.0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>Audio Recording</h2>\n",
    "Starts audio recording and detect wake word\n",
    "<h3>Say: \"Hey, Snips!\"</h3>"
   ],
   "id": "b7686457f1cc0da3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:45:44.334384Z",
     "start_time": "2025-11-30T22:45:20.784077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_queue = queue.Queue()\n",
    "audio_buffer = []\n",
    "\n",
    "tried_to_detect = False\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    audio_queue.put(indata.copy().flatten())\n",
    "\n",
    "with sd.InputStream(samplerate=SAMPLE_RATE,callback=callback):\n",
    "    try:\n",
    "        while True:    \n",
    "            new_audio = audio_queue.get()\n",
    "            #new_audio = librosa.resample(new_audio, orig_sr=MIC_RATE, target_sr=SAMPLE_RATE)\n",
    "            if new_audio is None:\n",
    "                continue\n",
    "            audio_buffer = np.concatenate((audio_buffer, new_audio))\n",
    "            if len(audio_buffer) > WINDOW_SAMPLES and not tried_to_detect:\n",
    "                is_detected = wake_word_detect(audio_buffer)\n",
    "                if (is_detected) :\n",
    "                    print(\"Wake Word Detected!\")\n",
    "                    sd.play(audio_buffer, SAMPLE_RATE)\n",
    "                    break\n",
    "                tried_to_detect = True\n",
    "            if len(audio_buffer) >= WINDOW_SAMPLES + STRIDE_SAMPLES:\n",
    "                audio_buffer = audio_buffer[int(STRIDE_SAMPLES):]\n",
    "                tried_to_detect = False\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting from keyboard interrupt\")\n",
    "        "
   ],
   "id": "6f0d7ff1db591480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.5023)\n",
      "tensor(-3.5307)\n",
      "tensor(-4.6720)\n",
      "tensor(-4.8157)\n",
      "tensor(-6.2468)\n",
      "tensor(-2.7570)\n",
      "tensor(-2.2642)\n",
      "tensor(-4.3235)\n",
      "tensor(-4.5635)\n",
      "tensor(-4.2110)\n",
      "tensor(-5.1627)\n",
      "tensor(-6.6498)\n",
      "tensor(-5.7129)\n",
      "tensor(-2.2449)\n",
      "tensor(3.7066)\n",
      "Wake Word Detected!\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ee90ee885651db3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
